\section{Referencial Teórico}
\label{sec:theory}

Esta seção visa a definir conceitos a serem utilizados ao longo do projeto, assim como mencionar trabalhos relacionados a fim de melhor explorar possibilidades de expansão do assunto.

O principal conceito a ser trabalhado neste projeto é o de inteligência artificial. Esse é um termo relativamente amplo, de forma que não há uma única definição para ele. Porém, uma das mais usadas é a de que IA é o estudo de como fazer computadores fazerem coisas em que pessoas são melhores \cite{ai-and-humanities}. Isso é, IA é o estudo de como capacitar computadores a melhor atender a necessidades que demandam características humanas, como a capacidade de raciocinar e tomar decisões.

Tendo como base IA, outros trabalhos podem ser citados a fim de realçar as possibilidades existentes para este projeto. O primeiro deles é o estudo de Imai (2022)\nocite{copilot-pair-programming}, no qual um breve experimento é conduzido a fim de definir a capacidade que o \textit{Github Copilot} tem de substituir a necessidade de um segundo desenvolvedor durante a prática de \textit{pair programming}, prática essa que consiste em dois desenvolvedores programarem em uma mesma máquina. Durante esse estudo foi observado que ao utilizar o \textit{Github Copilot} desenvolvedores acabam sendo mais produtivos, porém, a qualidade do código gerado é menor quando comparado ao código gerado por dois desenvolvedores trabalhando juntos.

Um segundo estudo interessante é o feito por Hourani et al. (2019)\nocite{ai-impact-in-testing}, no qual é analisado o impacto do uso de IA para testes de \textit{software}. Nesse estudo, é observado que a utilização de IA para testar sistemas tem o potencial de diminuir o tempo para que uma funcionalidade ou produto sejam lançados no mercado. Isso ocorre devido a capacidade que IA tem de analisar uma grande base de código a fim de encontrar possíveis \textit{bugs} e vulnerabilidades.

Também há espaço para que o artigo escrito por Prenner et al. (2022)\nocite{codex-bugfix} seja citado. Nesse, um experimento é conduzido a fim de verificar a capacidade que o \textit{Codex} tem de encontrar \textit{bugs} comparado a ferramentas específicas para essa funcionalidade. Para a execução da pesquisa foram utilizadas as linguagens Python e Java, sendo que, mesmo não tendo sido treinado com esse objetivo em mente, o modelo se apresentou eficaz em encontrar e resolver bugs, demonstrando sua capacidade de adaptação a diferentes cenários.

Por fim, pode ser mencionado o trabalho de Nguyen e Nadi (2022)\nocite{copilot-quality-evaluation}, no qual uma avaliação é feita a fim de medir a qualidade do código gerado pelo \textit{Github Copilot}. Nesse projeto os resultados apontam que, no geral, o código gerado tem complexidade baixa e uma assertividade média, não possuindo diferenças relevantes entre linguagens de programação. Um problema notável é que a ferramenta não se apresentou capaz de utilizar métodos auxiliares em suas sugestões, o que pode levar a funções mais complexas dependendo da regra de negócio implementada.

Tendo em vista os projetos citados, alguns estudos interessantes podem ser desenvolvidos a fim de melhor explorar o assunto. O primeiro é verificar a capacidade que IAs tem de fazer atualização automática de dependências que possuem \textit{breaking changes}, essas que são mudanças que quebram interfaces de comunicação entre a aplicação e sua dependência, uma dificuldade que se mostra comum no tópico de manutenção de sistemas. Outro ponto de interesse é a forma como a utilização de IAs pode acelerar o desenvolvimento de sistemas ao mesmo tempo que garante um nível de qualidade para eles, seja por meio da implementação de testes automatizados ou por meio da geração de código que segue boas práticas de programação. Para ambos os tópicos mencionados, é possível focar na utilização de ferramentas de \textit{chatbot} como o \textit{Chat GPT}, já que, devido a sua recente disponibilização ao público, ainda não há um estudo profundo sobre os impactos do uso dessa ferramenta.
